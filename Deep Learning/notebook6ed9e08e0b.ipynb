{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\ndef read_data(file):\n    data=[]\n    with open(file,'r',encoding='utf-8') as f:\n        for line in (f.readlines()):\n            line = line.strip().replace(' ', '')\n            data.append(line)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:04.489172Z","iopub.execute_input":"2021-05-29T12:41:04.489535Z","iopub.status.idle":"2021-05-29T12:41:04.494427Z","shell.execute_reply.started":"2021-05-29T12:41:04.489503Z","shell.execute_reply":"2021-05-29T12:41:04.493606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=read_data(\"/kaggle/input/dataset/clr_conversation.txt\")\nprint(len(data))\ndata[:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:06.002174Z","iopub.execute_input":"2021-05-29T12:41:06.002531Z","iopub.status.idle":"2021-05-29T12:41:10.16697Z","shell.execute_reply.started":"2021-05-29T12:41:06.002501Z","shell.execute_reply":"2021-05-29T12:41:10.166088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dictionary(vocab_name):\n    print ('loading dictionary')\n    vocab, rev_vocab = {}, {}\n    with open(vocab_name, 'r',encoding='utf-8') as fin:\n        for line in fin:\n            i, w = line.strip().split()\n            vocab[str(w)] = int(i)\n            rev_vocab[int(i)] = str(w)\n    return vocab,rev_vocab\nvocab,rev_vocab=load_dictionary('/kaggle/input/dataset/vocab.txt')\nprint(len(vocab))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:12.494674Z","iopub.execute_input":"2021-05-29T12:41:12.494985Z","iopub.status.idle":"2021-05-29T12:41:12.52089Z","shell.execute_reply.started":"2021-05-29T12:41:12.494955Z","shell.execute_reply":"2021-05-29T12:41:12.52008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentence_to_id(sentence,vocab):\n    return [int(vocab.get(w, vocab.get('<UNK>'))) for w in sentence]\n\ndef prepare_text_data(text,max_length,vocab,eos):\n        text_id = []\n        text_weight = []\n        if eos==True:\n            for data in text:\n                sentence = sentence_to_id(data,vocab)\n                if len(sentence) >= max_length:\n                    text_id.append(sentence[:max_length-1] + [vocab.get('<EOS>')])\n                else:\n                    text_id.append(sentence + [vocab.get('<EOS>')] + [vocab.get('<PAD>')]*(max_length-1-len(sentence)))\n            text_id = np.asarray(text_id)\n            return text_id\n        else:\n            for data in text:\n                sentence = sentence_to_id(data,vocab)\n                if len(sentence) >= max_length:\n                    text_id.append(sentence[:max_length]) \n                else:\n                    text_id.append(sentence + [vocab.get('<PAD>')]*(max_length-len(sentence)))\n            text_id = np.asarray(text_id)\n            return text_id","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:17.549114Z","iopub.execute_input":"2021-05-29T12:41:17.549469Z","iopub.status.idle":"2021-05-29T12:41:17.557188Z","shell.execute_reply.started":"2021-05-29T12:41:17.549439Z","shell.execute_reply":"2021-05-29T12:41:17.556238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab.get('<PAD>')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:18.351437Z","iopub.execute_input":"2021-05-29T12:41:18.351772Z","iopub.status.idle":"2021-05-29T12:41:18.357067Z","shell.execute_reply.started":"2021-05-29T12:41:18.351742Z","shell.execute_reply":"2021-05-29T12:41:18.356156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y=data[:-1],data[1:]\nx_id=prepare_text_data(x,30,vocab,True)\nx_final=np.hstack((np.ones((x_id.shape[0],1)),x_id)).reshape(-1,31,1).astype(int)\ny_id=prepare_text_data(y,30,vocab,True)\ny_final=np.hstack((np.ones((y_id.shape[0],1)),y_id)).reshape(-1,31,1).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:41:19.406194Z","iopub.execute_input":"2021-05-29T12:41:19.406568Z","iopub.status.idle":"2021-05-29T12:42:32.04472Z","shell.execute_reply.started":"2021-05-29T12:41:19.406538Z","shell.execute_reply":"2021-05-29T12:42:32.043736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in range(5):\n #   print(x_id[i],y_final[i])\nprint(\"Code of start of sentence: \",vocab[\"<BOS>\"])\nprint(\"Code of end of sentence: \",vocab[\"<EOS>\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:42:32.046249Z","iopub.execute_input":"2021-05-29T12:42:32.046577Z","iopub.status.idle":"2021-05-29T12:42:32.051975Z","shell.execute_reply.started":"2021-05-29T12:42:32.04654Z","shell.execute_reply":"2021-05-29T12:42:32.051159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:42:37.312971Z","iopub.execute_input":"2021-05-29T12:42:37.313316Z","iopub.status.idle":"2021-05-29T12:42:42.023707Z","shell.execute_reply.started":"2021-05-29T12:42:37.313282Z","shell.execute_reply":"2021-05-29T12:42:42.022629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1024\nsteps_per_epoch = len(x_final)//BATCH_SIZE\nprint(steps_per_epoch)\ndataset = tf.data.Dataset.from_tensor_slices((x_final,y_final)).shuffle(1500).batch(BATCH_SIZE, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:42:45.247102Z","iopub.execute_input":"2021-05-29T12:42:45.247487Z","iopub.status.idle":"2021-05-29T12:42:48.130351Z","shell.execute_reply.started":"2021-05-29T12:42:45.247455Z","shell.execute_reply":"2021-05-29T12:42:48.129539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"physical_devices = tf.config.list_physical_devices('GPU') \nprint(physical_devices)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:22.620527Z","iopub.execute_input":"2021-05-29T12:43:22.620853Z","iopub.status.idle":"2021-05-29T12:43:22.624947Z","shell.execute_reply.started":"2021-05-29T12:43:22.620823Z","shell.execute_reply":"2021-05-29T12:43:22.624182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding,Input,LSTM,TimeDistributed,Dense,GRU\nfrom tensorflow.keras.layers import RepeatVector, Activation, Lambda ,Concatenate ,Dot","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:23.850661Z","iopub.execute_input":"2021-05-29T12:43:23.850969Z","iopub.status.idle":"2021-05-29T12:43:23.855078Z","shell.execute_reply.started":"2021-05-29T12:43:23.85094Z","shell.execute_reply":"2021-05-29T12:43:23.854114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def softmax(x, axis=1):\n    ndim = K.ndim(x)\n    if ndim == 2:\n        return K.softmax(x)\n    elif ndim > 2:\n        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n        s = K.sum(e, axis=axis, keepdims=True)\n        return e / s\n    else:\n        raise ValueError('Cannot apply softmax to a tensor that is 1D')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:24.847913Z","iopub.execute_input":"2021-05-29T12:43:24.848272Z","iopub.status.idle":"2021-05-29T12:43:24.854223Z","shell.execute_reply.started":"2021-05-29T12:43:24.848235Z","shell.execute_reply":"2021-05-29T12:43:24.853372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"repeator = RepeatVector(31)\nconcatenator = Concatenate(axis=-1)\ndensor1 = Dense(10, activation = \"tanh\")\ndensor2 = Dense(1, activation = \"relu\")\nactivator = Activation(softmax, name='attention_weights') \ndotor = Dot(axes = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:25.698182Z","iopub.execute_input":"2021-05-29T12:43:25.698529Z","iopub.status.idle":"2021-05-29T12:43:25.714742Z","shell.execute_reply.started":"2021-05-29T12:43:25.6985Z","shell.execute_reply":"2021-05-29T12:43:25.714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_step_attention(a, s_prev):\n    s_prev = repeator(s_prev)\n    concat = concatenator([a,s_prev])\n    e = densor1(concat)\n    energies = densor2(e)\n    alphas = activator(energies)\n    context = dotor([alphas,a])\n    return context","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:26.497156Z","iopub.execute_input":"2021-05-29T12:43:26.497604Z","iopub.status.idle":"2021-05-29T12:43:26.507471Z","shell.execute_reply.started":"2021-05-29T12:43:26.497561Z","shell.execute_reply":"2021-05-29T12:43:26.50636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_model():\n    enc_input = Input((31,))\n    enc_embed = Embedding(len(vocab) + 1, 100,mask_zero=True)(enc_input)\n    hidden = GRU(100, return_sequences=True)(enc_embed)\n    output, state= GRU(100,return_sequences=True,return_state=True)(hidden)\n    encoder=tf.keras.Model(enc_input,[output, state])\n    return encoder\nencoder=encoder_model()\ndef decoder_model():\n    h_init= Input(shape=(100,))\n    dec_input = Input((1,))\n    encoder_z=Input((31,100))\n    h=h_init\n    \n    context = one_step_attention(encoder_z, h)\n    embed=Embedding(len(vocab) + 1, 100,mask_zero=True)(dec_input)\n    merge=tf.concat([embed, context], axis=-1)\n    \n    hidden=GRU(100, return_sequences=True)(merge)\n    output, state=GRU(100, return_state = True)(hidden) \n    out=Dense(len(vocab), activation='softmax')(output)\n    decoder=tf.keras.Model([encoder_z,h_init,dec_input],[out,state])\n    return decoder\ndecoder=decoder_model()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:27.244352Z","iopub.execute_input":"2021-05-29T12:43:27.244658Z","iopub.status.idle":"2021-05-29T12:43:29.312869Z","shell.execute_reply.started":"2021-05-29T12:43:27.244631Z","shell.execute_reply":"2021-05-29T12:43:29.312041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:29.314376Z","iopub.execute_input":"2021-05-29T12:43:29.314715Z","iopub.status.idle":"2021-05-29T12:43:29.320765Z","shell.execute_reply.started":"2021-05-29T12:43:29.314679Z","shell.execute_reply":"2021-05-29T12:43:29.319783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@tf.function\ndef train_step(inp, targ,batch_size):\n    loss = 0\n    with tf.GradientTape() as tape:\n        enc_output, enc_hidden= encoder(inp)\n        dec_hidden =  enc_hidden    \n        dec_input = targ[:, 0]\n        for t in range(1,31):\n            predictions, dec_hidden = decoder([enc_output, dec_hidden, dec_input])\n            loss += loss_function(targ[:, t], predictions)\n            dec_input=targ[:, t]\n    batch_loss = (loss / int(targ.shape[1]))\n    variables = encoder.trainable_variables + decoder.trainable_variables\n    gradients = tape.gradient(loss, variables)\n    optimizer.apply_gradients(zip(gradients, variables))\n    return batch_loss","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:29.322741Z","iopub.execute_input":"2021-05-29T12:43:29.323099Z","iopub.status.idle":"2021-05-29T12:43:29.332977Z","shell.execute_reply.started":"2021-05-29T12:43:29.323059Z","shell.execute_reply":"2021-05-29T12:43:29.332231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_sequence_with_greedy_search(input_seq):\n    enc_output, enc_hidden= encoder(input_seq)\n    dec_hidden =  enc_hidden    \n    dec_input=np.array([vocab['<BOS>']])\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        y_hat, dec_hidden = decoder([enc_output, dec_hidden, dec_input])\n \n        sampled_token_index = np.argmax(y_hat)\n        sampled_char = rev_vocab[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        if sampled_char == '<EOS>' or len(decoded_sentence) > 29:\n            stop_condition = True\n   \n        dec_input=np.array([vocab[sampled_char]])\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:31.29459Z","iopub.execute_input":"2021-05-29T12:43:31.294929Z","iopub.status.idle":"2021-05-29T12:43:31.301236Z","shell.execute_reply.started":"2021-05-29T12:43:31.2949Z","shell.execute_reply":"2021-05-29T12:43:31.300029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input=read_data(\"/kaggle/input/simple-test/input.txt\")\nprint(test_input[:8])\ntest_id=prepare_text_data(test_input,30,vocab,True)\ntest_final=np.hstack((np.ones((test_id.shape[0],1)),test_id)).reshape(-1,31,1).astype(int)\n#print(test_final[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:43:32.665612Z","iopub.execute_input":"2021-05-29T12:43:32.66593Z","iopub.status.idle":"2021-05-29T12:43:32.680953Z","shell.execute_reply.started":"2021-05-29T12:43:32.6659Z","shell.execute_reply":"2021-05-29T12:43:32.680009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 30\nimport time\nfor epoch in range(EPOCHS):\n    start = time.time()\n    total_loss = 0\n    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):  \n        batch_loss = train_step(inp, targ , 1024)\n        total_loss += batch_loss\n        if batch % 700 == 0:\n            print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n    encoder.save('encoder_model_'+str(epoch+1), save_format='tf')\n    decoder.save('decoder_model_'+str(epoch+1), save_format='tf')\n    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n') \n    for i in range(len(test_input)):\n        cur=test_final[i].reshape(-1,31,1)\n        ans=decode_sequence_with_greedy_search(cur)\n        print(test_input[i]+\"   \"+ans)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:45:00.228716Z","iopub.execute_input":"2021-05-29T12:45:00.229041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def beam_search_predictions(data, beam_index = 3):\n    start=[vocab['<BOS>']]\n    start_word = np.array([[start, 0.0]])\n    while len(start_word[0][0]) < 29:\n        temp = []\n        for s in start_word:\n            \n            \n            enc_output, enc_hidden= encoder(data)\n            dec_hidden =  enc_hidden    \n            dec_input=np.array([s[0][-1]])\n            preds, dec_hidden = decoder([enc_output, dec_hidden, dec_input])\n          \n            word_preds = np.argsort(preds[0])[-beam_index:]\n            # Getting the top <beam_index>(n) predictions and creating a \n            # new list so as to put them via the model again\n            for w in list(word_preds):\n                next_cap, prob = s[0][:], s[1]\n                next_cap.append(w)\n  \n                prob += preds[0][w]\n                temp.append([next_cap, prob])\n            \n        start_word = temp\n        \n        # Sorting according to the probabilities\n        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n        # Getting the top words\n        start_word = start_word[-beam_index:]\n    \n    start_word = start_word[-1][0]\n    intermediate_caption = [rev_vocab[i] for i in start_word]\n\n    final_caption = []\n    \n    for i in intermediate_caption:\n        if i != '<EOS>':\n            final_caption.append(i)\n        else:\n            break\n    \n    final_caption = ''.join(final_caption[1:])\n    return final_caption","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:52:29.956804Z","iopub.execute_input":"2021-05-29T23:52:29.957223Z","iopub.status.idle":"2021-05-29T23:52:29.970901Z","shell.execute_reply.started":"2021-05-29T23:52:29.957139Z","shell.execute_reply":"2021-05-29T23:52:29.969964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_input[1])\nbeam_search_predictions(test_id[1].reshape(-1,31,1), beam_index = 5)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T06:30:15.060482Z","iopub.status.busy":"2021-05-26T06:30:15.060114Z","iopub.status.idle":"2021-05-26T06:30:18.005078Z","shell.execute_reply":"2021-05-26T06:30:18.004146Z","shell.execute_reply.started":"2021-05-26T06:30:15.060449Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_input[2])\nbeam_search_predictions(test_final[2].reshape(-1,31,1), beam_index = 5)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T06:30:19.165521Z","iopub.status.busy":"2021-05-26T06:30:19.165204Z","iopub.status.idle":"2021-05-26T06:30:21.991011Z","shell.execute_reply":"2021-05-26T06:30:21.990342Z","shell.execute_reply.started":"2021-05-26T06:30:19.165491Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_input[3])\nbeam_search_predictions(test_final[3].reshape(-1,31,1), beam_index = 5)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T06:31:11.784718Z","iopub.status.busy":"2021-05-26T06:31:11.784392Z","iopub.status.idle":"2021-05-26T06:31:18.843749Z","shell.execute_reply":"2021-05-26T06:31:18.843056Z","shell.execute_reply.started":"2021-05-26T06:31:11.784687Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_input[4])\nbeam_search_predictions(test_final[4].reshape(-1,31,1), beam_index = 5)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T06:31:30.031208Z","iopub.status.busy":"2021-05-26T06:31:30.030876Z","iopub.status.idle":"2021-05-26T06:31:38.167815Z","shell.execute_reply":"2021-05-26T06:31:38.167089Z","shell.execute_reply.started":"2021-05-26T06:31:30.031178Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_input[5])\nbeam_search_predictions(test_final[5].reshape(-1,31,1), beam_index = 5)","metadata":{"execution":{"iopub.execute_input":"2021-05-26T06:32:31.003449Z","iopub.status.busy":"2021-05-26T06:32:31.003121Z","iopub.status.idle":"2021-05-26T06:32:38.189774Z","shell.execute_reply":"2021-05-26T06:32:38.188952Z","shell.execute_reply.started":"2021-05-26T06:32:31.00342Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}