{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa1806c15bc34f91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Problem Statement\n",
    "\n",
    "In this programming assignment, your task is to classify geographical locations according to their predicted tree cover using Gradient Boosting and Random Forest classifiers. You are expected to fill in functions that would complete this task. All of the necessary helper code is included in this notebook. However, we advise you to go over the slides, lecture material, the EdX videos and the corresponding notebooks before you attempt this Programming Assignment. You can find information about the dataset to be used in the following links:\n",
    "\n",
    "* **Dataset:** http://archive.ics.uci.edu/ml/datasets/Covertype \n",
    "\n",
    "* **Dataset description:** http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa1806c15c34f91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To time the entire solution\n",
    "import time\n",
    "start_nb = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a77b283c3c040501",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3dc492f41da1397e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from os.path import exists\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e66236b3e86ecf9f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Cover Types: {1.0: 'Spruce/Fir', 2.0: 'Lodgepole Pine', 3.0: 'Ponderosa Pine', 4.0: 'Cottonwood/Willow', 5.0: 'Aspen', 6.0: 'Douglas-fir', 7.0: 'Krummholz'}\n"
     ]
    }
   ],
   "source": [
    "#define a dictionary of cover types\n",
    "CoverTypes={1.0: 'Spruce/Fir',\n",
    "            2.0: 'Lodgepole Pine',\n",
    "            3.0: 'Ponderosa Pine',\n",
    "            4.0: 'Cottonwood/Willow',\n",
    "            5.0: 'Aspen',\n",
    "            6.0: 'Douglas-fir',\n",
    "            7.0: 'Krummholz' }\n",
    "print('Tree Cover Types:', CoverTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-601dbde74a330c36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\POPO\\\\Downloads\\\\pa6\\\\pa6'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getcwd()\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee2d7617e6961570",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Break up features that are made out of several binary features.\n",
    "def get_columns(cols_txt):\n",
    "    cols=[a.strip() for a in cols_txt.split(',')]\n",
    "    colDict={a:[a] for a in cols}\n",
    "    colDict['Soil_Type (40 binary columns)'] = ['ST_'+str(i) for i in range(40)]\n",
    "    colDict['Wilderness_Area (4 binarycolumns)'] = ['WA_'+str(i) for i in range(4)]\n",
    "    columns=[]\n",
    "    for item in cols:\n",
    "        columns = columns + colDict[item]\n",
    "    return columns\n",
    "    #print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63c74c999a27b45f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the feature names\n",
    "cols_txt=\"\"\"\n",
    "Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n",
    "Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n",
    "Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n",
    "Horizontal_Distance_To_Fire_Points, Wilderness_Area (4 binarycolumns), \n",
    "Soil_Type (40 binary columns), Cover_Type\n",
    "\"\"\"\n",
    "columns = get_columns(cols_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-39425dea9979acb3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Read the file into an RDD\n",
    "# When using sc.textRead you need to use an absolute path.\n",
    "# If doing this on a real cluster, you need the file to be available on all nodes, ideally in HDFS.\n",
    "path=file_path + '/covtype/covtype.data'\n",
    "inputRDD=sc.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputRDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6329e83b6ee7fd32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Helper Functions\n",
    "Here are some helper functions that you will have to fill up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c67efb471217986",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### label_RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfb574e5ebeb330c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The function <font color=\"blue\">label_RDD</font> takes an RDD as input and returns an RDD of labeled points\n",
    "\n",
    "Input: RDD consisting of a string with comma separated values (InputRDD)\n",
    "\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "'2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5'\n",
    "```\n",
    "Output: RDD of the type LabeledPoint with the first element being the label and second element being a DenseVector that contains all the elements of the InputRDD(Except the last value which is the label).\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def label_RDD(inputRDD):\n",
    "    Data=inputRDD.map(lambda x:x.split(\",\")).map(lambda x:LabeledPoint(x[-1],x[:-1]))\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7ffe45353a6d5ad",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = label_RDD(inputRDD)\n",
    "Data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "labelRDD",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Data.first().label == 5.0\n",
    "assert Data.first().features == Vectors.dense([2596.0, 51.0, 3.0, 258.0, 0.0, 510.0, 221.0, 232.0, 148.0, 6279.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-515fa560228469b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### count_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27a14578d81eed8c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The function <font color=\"blue\">count_examples</font> takes an RDD as input and returns count of number of labels belonging to each class\n",
    "\n",
    "Input: RDD obtained as the output of the labelRDD\n",
    "\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "[LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    " LabeledPoint(5.0, [2590.0,56.0,2.0,212.0,-6.0,390.0,220.0,235.0,151.0,6225.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
    " LabeledPoint(2.0, [2804.0,139.0,9.0,268.0,65.0,3180.0,234.0,238.0,135.0,6121.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]\n",
    "```\n",
    "Output: list of tuples (label, count)\n",
    "\n",
    "**NOTE: The outputs need to be sorted in descending order by counts**\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "[(5.0, 2), (2.0, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad446944695ea686",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def count_examples(Data):\n",
    "    return Data.map(lambda x:(x.label,1)).groupByKey().mapValues(lambda x: sum(x)).sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a678d8b03134f4bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "counts = count_examples(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a585400e9d239e42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.0, 2), (2.0, 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts3 = count_examples(sc.parallelize(Data.take(3)))\n",
    "counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_tc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(counts3) == list, 'Incorrect return type'\n",
    "assert type(counts3[0]) == tuple, 'Incorrect return type'\n",
    "assert type(counts3[0][0]) == float, 'Incorrect return type'\n",
    "assert type(counts3[0][1]) == int, 'Incorrect return type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_vc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert counts3[0][0] == 5.0, 'Incorrect return value'\n",
    "assert counts3[0][1] == 2, 'Incorrect return value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "countRDD_vch",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-019033d0bb8c2c73",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size= 581012\n",
      "              type (label):   percent of total\n",
      "---------------------------------------------------------\n",
      "           Krummholz (7.0):\t3.53\n",
      "         Douglas-fir (6.0):\t2.99\n",
      "               Aspen (5.0):\t1.63\n",
      "   Cottonwood/Willow (4.0):\t0.47\n",
      "      Ponderosa Pine (3.0):\t6.15\n",
      "      Lodgepole Pine (2.0):\t48.76\n",
      "          Spruce/Fir (1.0):\t36.46\n"
     ]
    }
   ],
   "source": [
    "total=Data.count()\n",
    "print('total data size=',total)\n",
    "print('              type (label):   percent of total')\n",
    "print('---------------------------------------------------------')\n",
    "print('\\n'.join(['%20s (%3.1f):\\t%4.2f'%(CoverTypes[a[0]],a[0],100.0*a[1]/float(total)) for a in counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34f8bbfc6a5a83b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### labels_to_binary (Making the problem binary)\n",
    "\n",
    "The implementation of BoostedGradientTrees in MLLib supports only binary problems. the `CovType` problem has\n",
    "7 classes. To make the problem binary we choose the `Lodgepole Pine` (label = 2.0). We therefore transform the dataset to a new dataset where the label is `1.0` is the class is `Lodgepole Pine` and is `0.0` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8fcdc59eb2f4e08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The function <font color=\"blue\">labels_to_binary</font> takes an RDD as input and returns an RDD with binary labels\n",
    "such that: \n",
    "\n",
    "```python\n",
    "if label == 2:      #Since label 2 has the highest count value\n",
    "    new_label = 1\n",
    "    \n",
    "else:\n",
    "    new_label = 0\n",
    "```\n",
    "\n",
    "Input: Labelled RDD (Output from <font color=\"blue\">label_RDD</font> function)\n",
    "\n",
    "\n",
    "**<font color=\"magenta\" size=2>Example Input</font>**\n",
    "``` python\n",
    "LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```\n",
    "Output: The same RDD with label of all entries as 0 except for label = 2.0 where label becomes 1.0\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "LabeledPoint(0.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68e335dc015340e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def change(x):\n",
    "    if x==2.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "def labels_to_binary(Data):\n",
    "    Data=Data.map(lambda x:LabeledPoint(change(x.label),x.features))\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0099fa01e48236a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data= labels_to_binary(Data)\n",
    "Data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "L2B_vc",
     "locked": true,
     "points": "4",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Data.first().label == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eee681d192a47b23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducing data size\n",
    "For this assignment, we will use only 10% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7daae8ed96a71326",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trainingData = sc.parallelize(pickle.load(open('training10p.pkl', 'rb')))\n",
    "testData = sc.parallelize(pickle.load(open('test10p.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d12b5d6c39a98a8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: Data1=58100, trainingData=40682, testData=17418\n"
     ]
    }
   ],
   "source": [
    "print('Sizes: Data1=%d, trainingData=%d, testData=%d'%(trainingData.cache().count() + testData.cache().count(),trainingData.cache().count(),testData.cache().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d06ade87c62cad8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "counts = count_examples(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01b29807a18bdaa8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-338feb954dbc4325",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Following [this example](http://spark.apache.org/docs/latest/mllib-ensembles.html#classification) from the mllib documentation\n",
    "\n",
    "* [pyspark.mllib.trees documentation](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.GradientBoostedTrees)\n",
    "\n",
    "### Main classes and methods\n",
    "\n",
    "* `GradientBoostedTrees` is the class that implements the learning trainClassifier,\n",
    "   * It's main method is `trainClassifier(trainingData)` which takes as input a training set and generates an instance of `GradientBoostedTreesModel`\n",
    "   * The main parameter from train Classifier are:\n",
    "      * **data** – Training dataset: RDD of LabeledPoint. Labels should take values {0, 1}.\n",
    "      * categoricalFeaturesInfo – Map storing arity of categorical features. E.g., an entry (n -> k) indicates that feature n is categorical with k categories indexed from 0: {0, 1, ..., k-1}.\n",
    "      * **loss** – Loss function used for minimization during gradient boosting. Supported: {“logLoss” (default), “leastSquaresError”, “leastAbsoluteError”}.\n",
    "      * **numIterations** – Number of iterations of boosting. (default: 100)\n",
    "      * **learningRate** – Learning rate for shrinking the contribution of each estimator. The learning rate should be between in the interval (0, 1]. (default: 0.1)\n",
    "      * **maxDepth** – Maximum depth of the tree. E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 3)\n",
    "      * **maxBins** – maximum number of bins used for splitting features (default: 32) DecisionTree requires maxBins >= max categories\n",
    "      \n",
    "      \n",
    "* `GradientBoostedTreesModel` represents the output of the boosting process: a linear combination of classification trees. The methods supported by this class are:\n",
    "   * `save(sc, path)` : save the tree to a given filename, sc is the Spark Context.\n",
    "   * `load(sc,path)` : The counterpart to save - load classifier from file.\n",
    "   * `predict(X)` : predict on a single datapoint (the `.features` field of a `LabeledPont`) or an RDD of datapoints.\n",
    "   * `toDebugString()` : print the classifier in a human readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7476b6ae9251c7dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "The function <font color=\"blue\">Classify_GB</font> takes as inputs:\n",
    "\n",
    "1. **trainingData**: Training data (Type: RDD)\n",
    "2. **testData**: Test data (Type: RDD)\n",
    "3. **maxDepth**: Depth of tree (Type: int)\n",
    "\n",
    "The function trains a GradientBoostedTrees classifier and returns the error\n",
    "\n",
    "**Output**: error (Type: float)\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "error=0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [2503.0,157.0,4.0,67.0,4.0,674.0,224.0,240.0,151.0,5600.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-510b89e35e626b95",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9bdfd4c81113b03",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2137444023424044"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "import numpy as np\n",
    "def Classify_GB(trainingData, testData, maxDepth):\n",
    "    model = GradientBoostedTrees.trainClassifier(data=trainingData,categoricalFeaturesInfo={},maxDepth=maxDepth)\n",
    "    pre=np.array(model.predict(testData.map(lambda x:x.features)).collect())\n",
    "    true=np.array(testData.map(lambda x:x.label).collect())\n",
    "    error=np.mean(pre!=true)\n",
    "    return error\n",
    "Classify_GB(trainingData, testData, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a1bfa5a1b06be15",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_1_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "visible_results=pickle.load(open('GradientBoostingResultsVisible.pkl','rb'))\n",
    "assert Classify_GB(trainingData, testData, 1) <= visible_results['B_10p_1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_3_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Classify_GB(trainingData, testData, 3) <= visible_results['B_10p_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_6_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyGB_10_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ad76a0d80b6bf27",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6d017e3cabd3763",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "* Following [this example](http://spark.apache.org/docs/latest/mllib-ensembles.html#classification) from the mllib documentation\n",
    "\n",
    "* [pyspark.mllib.trees.RandomForest documentation](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.tree.RandomForest)\n",
    "\n",
    "**trainClassifier**`(data, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy='auto', impurity='gini', maxDepth=4, maxBins=32, seed=None)`   \n",
    "Method to train a decision tree model for binary or multiclass classification.\n",
    "\n",
    "**Parameters:**  \n",
    "* *data* – Training dataset: RDD of LabeledPoint. Labels should take values {0, 1, ..., numClasses-1}.  \n",
    "* *numClasses* – number of classes for classification.  \n",
    "* *categoricalFeaturesInfo* – Map storing arity of categorical features. E.g., an entry (n -> k) indicates that feature n is categorical with k categories indexed from 0: {0, 1, ..., k-1}.  \n",
    "* *numTrees* – Number of trees in the random forest.  \n",
    "* *featureSubsetStrategy* – Number of features to consider for splits at each node. Supported: “auto” (default), “all”, “sqrt”, “log2”, “onethird”. If “auto” is set, this parameter is set based on numTrees: if numTrees == 1, set to “all”; if numTrees > 1 (forest) set to “sqrt”.\n",
    "* *impurity* – Criterion used for information gain calculation. Supported values: “gini” (recommended) or “entropy”.  \n",
    "* *maxDepth* – Maximum depth of the tree. E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 4)  \n",
    "* *maxBins* – maximum number of bins used for splitting features (default: 32)\n",
    "* *seed* – Random seed for bootstrapping and choosing feature subsets.  \n",
    "\n",
    "**Returns:**\t\n",
    "RandomForestModel that can be used for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ce39d0a147d4c4b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Example\n",
    "The function <font color=\"blue\">Classify_RF</font> takes as inputs:\n",
    "\n",
    "1. **trainingData**: Training data (Type: RDD)\n",
    "2. **testData**: Test data (Type: RDD)\n",
    "3. **maxDepth**: Depth of tree (Type: int)\n",
    "\n",
    "The function trains a RandomForest classifier and returns the error in classification\n",
    "\n",
    "**Output**: error (Type: float)\n",
    "\n",
    "**<font color=\"blue\" size=2>Example Output</font>**\n",
    "``` python\n",
    "error=0.3\n",
    "```\n",
    "\n",
    "Note: You are allowed to alter the number of trees parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2d098cb8b35b026",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1772af5d3c6c0273",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## Insert your answer in this cell. DO NOT CHANGE THE NAME OF THE FUNCTION.\n",
    "def Classify_RF(trainingData, testData, depth):    \n",
    "    model = RandomForest.trainClassifier(data=trainingData,numClasses=2,categoricalFeaturesInfo={},numTrees=500,maxDepth=depth)\n",
    "    pre=np.array(model.predict(testData.map(lambda x:x.features)).collect())\n",
    "    true=np.array(testData.map(lambda x:x.label).collect())\n",
    "    error=np.mean(pre!=true)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d17c1ba1cd3b333",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_3_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "visible_results_rf=pickle.load(open('RandomForestResultsVisible.pkl','rb'))\n",
    "assert Classify_RF(trainingData, testData, 3) <= visible_results_rf['RF_10p_3'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_6_v",
     "locked": true,
     "points": "5",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Classify_RF(trainingData, testData, 6) <= visible_results_rf['RF_10p_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_8_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "classifyRF_10_h",
     "locked": true,
     "points": "15",
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden Tests here\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  647.9281346797943\n"
     ]
    }
   ],
   "source": [
    "end_nb = time.time()\n",
    "print(\"Total time taken: \", end_nb - start_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
