{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this reading notebook you will learn how to retain the state of an RNN when processing long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far you have trained RNNs on entire sequences, possibly of varying length. In some applications, such as financial time series modeling or real-time speech processing, the input sequence can be very long. \n",
    "\n",
    "One way to process such sequences is to simply chop up the sequences into separate batches. However, the internal state of the RNN would then normally be reset in between the batches. Persisting an RNN cell's state between batches is useful in such contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful and non-stateful RNN models\n",
    "We will begin by creating two versions of the same RNN model. The first is a regular RNN that does not retain its state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regular (non-stateful) RNN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "gru = Sequential([\n",
    "    GRU(5, input_shape=(None, 1), name='rnn')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To persist RNN cell states between batches, you can use the `stateful` argument when you initialize an RNN layer. The default value of this argument is `False`. This argument is available for all RNN layer types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stateful RNN\n",
    "\n",
    "stateful_gru = Sequential([\n",
    "    GRU(5, stateful=True, batch_input_shape=(2, None, 1), name='stateful_rnn')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as well as setting `stateful=True`, we have also specified the `batch_input_shape`. This fixes the number of elements in a batch, as well as providing the sequence length and number of features. So the above model will always require a batch of 2 sequences.\n",
    "\n",
    "When using stateful RNNs, it is necessary to supply this argument to the first layer of a `Sequential` model. `This is because the model will always assume that each element of every subsequent batch it receives will be a continuation of the sequence from the corresponding element in the previous batch.`\n",
    "\n",
    "Another detail is that when defining a model with a stateful RNN using the functional API, you will need to specify the `batch_shape` argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the same stateful RNN using the functional API\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "inputs = Input(batch_shape=(2, None, 1))\n",
    "outputs = GRU(5, stateful=True, name='stateful_rnn')(inputs)\n",
    "\n",
    "stateful_gru = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the RNN states\n",
    "We can inspect the RNN layer states by retrieving the recurrent layer from each model, and looking at the `states` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "gru.get_layer('rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the internal state of the stateful RNN has a state stored for each element in a batch, which is why the shape of the state Variable is `(2, 5)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple sequence dataset\n",
    "We will demonstrate the effect of statefulness on a simple sequence dataset consisting of two sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 9, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the sequence dataset\n",
    "\n",
    "sequence_data = tf.constant([\n",
    "    [[-4.], [-3.], [-2.], [-1.], [0.], [1.], [2.], [3.], [4.]],\n",
    "    [[-40.], [-30.], [-20.], [-10.], [0.], [10.], [20.], [30.], [40.]]\n",
    "], dtype=tf.float32)\n",
    "sequence_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the sequence batch with both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see what happens when you pass the batch of sequences through either model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the batch with both models\n",
    "\n",
    "_1 = gru(sequence_data)\n",
    "_2 = stateful_gru(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "gru.get_layer('rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[-0.85203505,  0.4598765 , -0.97114426, -0.52167135, -0.9383196 ],\n",
       "        [-0.99996865, -0.6449878 , -1.        ,  0.50438094, -1.        ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stateful RNN model has updated and retained its state after having processed the input sequence batch. This internal state could then be used as the initial state for processing a continuation of both sequences in the next batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting the internal state\n",
    "If you need a stateful RNN to forget (or re-initialise) its state, then you can call an RNN layer's `reset_states()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the internal state of the stateful RNN model\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the RNN layer and inspect the internal state\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `reset_states()` resets the state to `0.`, which is the default initial state for the RNN layers in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retaining internal state across batches\n",
    "Passing a sequence to a stateful layer as several subsequences produces the same final output as passing the whole sequence at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn_1/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[-5.6025639e-02,  3.9827275e-01, -2.1747732e-01,  2.6507869e-01,\n",
       "          2.5313458e-01],\n",
       "        [ 7.7683464e-02,  2.3546161e-01,  9.6370751e-04,  9.8386025e-01,\n",
       "         -1.6556926e-01]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the internal state of the stateful RNN model and process the full sequences\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()\n",
    "_ = stateful_gru(sequence_data)\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch: tf.Tensor(\n",
      "[[[ -4.]\n",
      "  [ -3.]\n",
      "  [ -2.]]\n",
      "\n",
      " [[-40.]\n",
      "  [-30.]\n",
      "  [-20.]]], shape=(2, 3, 1), dtype=float32)\n",
      "\n",
      "Second batch: tf.Tensor(\n",
      "[[[ -1.]\n",
      "  [  0.]\n",
      "  [  1.]]\n",
      "\n",
      " [[-10.]\n",
      "  [  0.]\n",
      "  [ 10.]]], shape=(2, 3, 1), dtype=float32)\n",
      "\n",
      "Third batch: tf.Tensor(\n",
      "[[[ 2.]\n",
      "  [ 3.]\n",
      "  [ 4.]]\n",
      "\n",
      " [[20.]\n",
      "  [30.]\n",
      "  [40.]]], shape=(2, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Break the sequences into batches\n",
    "\n",
    "sequence_batch1 = sequence_data[:, :3, :]\n",
    "sequence_batch2 = sequence_data[:, 3:6, :]\n",
    "sequence_batch3 = sequence_data[:, 6:, :]\n",
    "\n",
    "print(\"First batch:\", sequence_batch1)\n",
    "print(\"\\nSecond batch:\", sequence_batch2)\n",
    "print(\"\\nThird batch:\", sequence_batch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first element in every batch is part of the same sequence, and the second element in every batch is part of the same sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'stateful_rnn_1/Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
       " array([[-5.6025639e-02,  3.9827275e-01, -2.1747732e-01,  2.6507869e-01,\n",
       "          2.5313458e-01],\n",
       "        [ 7.7683464e-02,  2.3546161e-01,  9.6370751e-04,  9.8386025e-01,\n",
       "         -1.6556926e-01]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the internal state of the stateful RNN model and process the batches in order\n",
    "\n",
    "stateful_gru.get_layer('stateful_rnn').reset_states()\n",
    "_ = stateful_gru(sequence_batch1)\n",
    "_ = stateful_gru(sequence_batch2)\n",
    "_ = stateful_gru(sequence_batch3)\n",
    "stateful_gru.get_layer('stateful_rnn').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the internal state of the stateful RNN after processing each batch is the same as it was earlier when we processed the entire sequence at once.\n",
    "\n",
    "This property can be used when training stateful RNNs, if we ensure that each example in a batch is a continuation of the same sequence as the corresponding example in the previous batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading and resources\n",
    "* https://www.tensorflow.org/guide/keras/rnn#cross-batch_statefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
