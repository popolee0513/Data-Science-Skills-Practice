{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write an AI to parse sentences and extract noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "TERMINALS = \"\"\"\n",
    "Adj -> \"country\" | \"dreadful\" | \"enigmatical\" | \"little\" | \"moist\" | \"red\"\n",
    "Adv -> \"down\" | \"here\" | \"never\"\n",
    "Conj -> \"and\"\n",
    "Det -> \"a\" | \"an\" | \"his\" | \"my\" | \"the\"\n",
    "N -> \"armchair\" | \"companion\" | \"day\" | \"door\" | \"hand\" | \"he\" | \"himself\"\n",
    "N -> \"holmes\" | \"home\" | \"i\" | \"mess\" | \"paint\" | \"palm\" | \"pipe\" | \"she\"\n",
    "N -> \"smile\" | \"thursday\" | \"walk\" | \"we\" | \"word\"\n",
    "P -> \"at\" | \"before\" | \"in\" | \"of\" | \"on\" | \"to\" | \"until\"\n",
    "V -> \"arrived\" | \"came\" | \"chuckled\" | \"had\" | \"lit\" | \"said\" | \"sat\"\n",
    "V -> \"smiled\" | \"tell\" | \"were\"\n",
    "\"\"\"\n",
    "\n",
    "NONTERMINALS = \"\"\"\n",
    "S -> N V\n",
    "S -> N V Det N\n",
    "S -> N V Det N P N\n",
    "S -> N V P Det Adj N Conj N V\n",
    "S -> Det N V Det Adj N\n",
    "\"\"\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(NONTERMINALS + TERMINALS)\n",
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent =\"she smiled\".split()\n",
    "#parser = nltk.ChartParser(grammar)\n",
    "#for tree in parser.parse(sent):\n",
    "    #print (tree) (S (N she) (V smiled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(sentence):\n",
    "    \"\"\"\n",
    "    Convert `sentence` to a list of its words.\n",
    "    Pre-process sentence by converting all characters to lowercase\n",
    "    and removing any word that does not contain at least one alphabetic\n",
    "    character.\n",
    "    \"\"\"\n",
    "    sentence= re.sub(r'[^\\w\\s]','',sentence)\n",
    "    sentence=sentence.split(\" \")\n",
    "    \n",
    "    final=[]\n",
    "    for i in sentence:\n",
    "        if i.isalpha():\n",
    "            final.append(i.lower())\n",
    "    return final\n",
    "def np_chunk(tree):\n",
    "    \"\"\"\n",
    "    Return a list of all noun phrase chunks in the sentence tree.\n",
    "    A noun phrase chunk is defined as any subtree of the sentence\n",
    "    whose label is \"NP\" that does not itself contain any other\n",
    "    noun phrases as subtrees.\n",
    "    \"\"\"\n",
    "    ans=[]\n",
    "    for i in range(len(tree)):\n",
    "        \n",
    "        if tree[i].label()==\"N\":\n",
    "            \n",
    "            ans.append(tree[i][0])\n",
    "    return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence=\"holmes sat.\"\n",
    "#sentence=preprocess(sentence)\n",
    "#s=list(parser.parse(sentence)) [Tree('S', [Tree('N', ['holmes']), Tree('V', ['sat'])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s[0][0].label())    N\n",
    "#print(s[0][1].label())    V\n",
    "#print(s[0])  (S (N holmes) (V sat))\n",
    "#print(s[0][0].label()==\"N\") True\n",
    "#print(s[0][0],s[0][1]) (N holmes) (V sat)\n",
    "#print(len(s[0])) 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # If filename specified, read sentence from file\n",
    "    if len(sys.argv) == 2:\n",
    "        with open(sys.argv[1]) as f:\n",
    "            s = f.read()\n",
    "\n",
    "    # Otherwise, get sentence as input\n",
    "    else:\n",
    "        s = input(\"Sentence: \")\n",
    "\n",
    "    # Convert input into list of words\n",
    "    s = preprocess(s)\n",
    "\n",
    "    # Attempt to parse sentence\n",
    "    try:\n",
    "        trees = list(parser.parse(s))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    if not trees:\n",
    "        print(\"Could not parse sentence.\")\n",
    "        return\n",
    "\n",
    "    # Print each tree with noun phrase chunks\n",
    "    for tree in trees:\n",
    "        tree.pretty_print()\n",
    "\n",
    "        print(\"Noun Phrase Chunks\")\n",
    "        for np in np_chunk(tree):\n",
    "            print(\" \".join(np.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Holmes sat.\n",
      "        S     \n",
      "   _____|___   \n",
      "  N         V \n",
      "  |         |  \n",
      "holmes     sat\n",
      "\n",
      "Noun Phrase Chunks\n",
      "holmes\n"
     ]
    }
   ],
   "source": [
    "#Exp 1\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Holmes lit a pipe.\n",
      "        S          \n",
      "   _____|_______    \n",
      "  N     V  Det  N  \n",
      "  |     |   |   |   \n",
      "holmes lit  a  pipe\n",
      "\n",
      "Noun Phrase Chunks\n",
      "holmes\n",
      "pipe\n"
     ]
    }
   ],
   "source": [
    "#Exp 2\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: We arrived the day before Thursday.\n",
      "             S                     \n",
      "  ___________|________________      \n",
      " N     V    Det  N    P       N    \n",
      " |     |     |   |    |       |     \n",
      " we arrived the day before thursday\n",
      "\n",
      "Noun Phrase Chunks\n",
      "we\n",
      "day\n",
      "thursday\n"
     ]
    }
   ],
   "source": [
    "#Exp 3\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Holmes sat in the red armchair and he chuckled.\n",
      "                    S                            \n",
      "   _________________|_______________________      \n",
      "  N     V   P  Det Adj    N     Conj  N     V    \n",
      "  |     |   |   |   |     |      |    |     |     \n",
      "holmes sat  in the red armchair and   he chuckled\n",
      "\n",
      "Noun Phrase Chunks\n",
      "holmes\n",
      "armchair\n",
      "he\n"
     ]
    }
   ],
   "source": [
    "#Exp 4\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: My companion smiled an enigmatical smile. \n",
      "                S                         \n",
      "  ______________|______________________    \n",
      "Det     N       V    Det     Adj       N  \n",
      " |      |       |     |       |        |   \n",
      " my companion smiled  an enigmatical smile\n",
      "\n",
      "Noun Phrase Chunks\n",
      "companion\n",
      "smile\n"
     ]
    }
   ],
   "source": [
    "#Exp 5\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
